##################################
1. 删除临时镜像
见http://stackoverflow.com/questions/33907835/docker-error-cannot-delete-docker-container-conflict-unable-to-remove-reposito。


##################################
2. 编译NVIDIA_CUDA-8.0_Samples报错：Makefile:381: recipe for target 'cudaDecodeGL' failed。
见http://stackoverflow.com/questions/42697716/failure-in-running-cuda-sample-after-cuda-8-0-installation的解决方案：find . -type f -execdir sed -i 's/UBUNTU_PKG_NAME = "nvidia-367"/UBUNTU_PKG_NAME = "nvidia-375"/g' '{}' \;
也可以参考：http://www.caffecn.cn/?/question/11091

##################################
docker可以支持把一个宿主机上的目录挂载到镜像里。

docker run -it -v /home/dock/Downloads:/usr/Downloads ubuntu64 /bin/bash

通过-v参数，冒号前为宿主机目录，必须为绝对路径，冒号后为镜像内挂载的路径。


##################################
Auto-Configuration Error: Cannot find cudnn.h at /usr/lib/x86_64-linux-gnu/include/cudnn.h
ln -s /usr/include/x86_64-linux-gnu/cudnn_v5.h /usr/lib/x86_64-linux-gnu/include/cudnn.h

##################################
Auto-Configuration Error: Cannot find cudnn.h at /usr/local/cuda/include/cudnn.h
 cp /usr/lib/x86_64-linux-gnu/include/cudnn.h /usr/local/cuda/include/cudnn.h

##################################
cd serving/tensorflow;./configure后报错java.lang.RuntimeException: Unrecoverable error while evaluating node 'REPOSITORY_DIRECTORY:@jemalloc'的解决方法：
apt-get install ca-certificates-java
update-ca-certificates -f

##################################
ERROR: no such target '@org_tensorflow//third_party/gpus/crosstool:crosstool': target 'crosstool' not declared in package 'third_party/gpus/crosstool' defined by /root/.cache/bazel/_bazel_root/8b00cc8fd020ef40da2b73b03747907f/external/org_tensorflow/third_party/gpus/crosstool/BUILD.
the crosstool in tools/bazel.rc is invalid (AFAIK). change @org_tensorflow//third_party/gpus/crosstool to @local_config_cuda//crosstool:toolchain.
the cuda_configure repository rule will fail (haven't looked in to why exactly), but essentially an bazel clean --expunge && export TF_NEED_CUDA=1 will fix this.

##################################
2017-04-07 12:09:17.939040: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda tensorflow_serving/...


bazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --config=cuda //tensorflow_serving/example:mnist_client

##################################
Auto-Configuration Error: Cannot find cuda library libcudnn.so.5
cp /usr/lib/x86_64-linux-gnu/libcudnn.so.5 /usr/local/cuda/lib64

##################################
$bazel-bin/tensorflow_serving/example/mnist_client --num_test=1000 --server=localhost:9000
D0701 17:42:35.348354769   17914 ev_posix.c:101]             Using polling engine: poll
('Extracting', '/tmp/train-images-idx3-ubyte.gz')
('Extracting', '/tmp/train-labels-idx1-ubyte.gz')
('Extracting', '/tmp/t10k-images-idx3-ubyte.gz')
('Extracting', '/tmp/t10k-labels-idx1-ubyte.gz')
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/usr/lib/python2.7/threading.py", line 810, in __bootstrap_inner
    self.run()
  File "/usr/lib/python2.7/threading.py", line 763, in run
    self.__target(*self.__args, **self.__kwargs)
  File "/home/work/.jumbo/lib/python2.7/site-packages/grpc/_channel.py", line 658, in _call_spin
    completed_call = event.tag(event)
  File "/home/work/.jumbo/lib/python2.7/site-packages/grpc/_channel.py", line 174, in handle_event
    callback()
  File "/home/work/.jumbo/lib/python2.7/site-packages/grpc/_channel.py", line 294, in <lambda>
    self._state.callbacks.append(lambda: fn(self))
  File "/home/work/.jumbo/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py", line 135, in <lambda>
    self._future.add_done_callback(lambda ignored_callback: fn(self))
  File "/home/work/huohuarong/serving/bazel-bin/tensorflow_serving/example/mnist_client.runfiles/tf_serving/tensorflow_serving/example/mnist_client.py", line 98, in <lambda>
    lambda result_future, l=label[0]: done(result_future, l))  # pylint: disable=cell-var-from-loop
  File "/home/work/huohuarong/serving/bazel-bin/tensorflow_serving/example/mnist_client.runfiles/tf_serving/tensorflow_serving/example/mnist_client.py", line 73, in done
    exception = result_future.exception()
  File "/home/work/.jumbo/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py", line 120, in exception
    return _abortion_error(rpc_error_call)
  File "/home/work/.jumbo/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py", line 74, in _abortion_error
    code = rpc_error_call.code()
AttributeError: 'NoneType' object has no attribute 'code'
看这里：https://github.com/tensorflow/serving/pull/351
需要再容器中:pip install 'grpcio>=1.1.3'
或者在Dockerfile.devel添加：pip install 'grpcio>=1.1.3'

##################################
>>> import tensorflow
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import *
  File "tensorflow/python/__init__.py", line 51, in <module>
    from tensorflow.python import pywrap_tensorflow
  File "tensorflow/python/pywrap_tensorflow.py", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File "tensorflow/python/pywrap_tensorflow.py", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
参考：http://stackoverflow.com/questions/35953210/error-running-basic-tensorflow-example
A common solution is to cd out of the /git/tensorflow directory before starting python or ipython.


##################################
bazel build -c opt --config=cuda tensorflow_serving/...

##################################
sudo nvidia-docker run -it -d -v /home/jindg/tool:/home/mnt jindg/tensorflow-serving-devel

##################################
nvidia-docker run --rm nvidia/cuda nvidia-smi


